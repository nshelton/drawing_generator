{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// voronoi  relaxation\n",
    "\n",
    "//grid based hatching\n",
    "\n",
    "// units are in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3192, 2256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import line as draw_line\n",
    "from skimage import data\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from skimage.transform import probabilistic_hough_line\n",
    "import random \n",
    "\n",
    "# Load image\"\n",
    "# image_path = \"/Users/nshelton/Pictures/gundam_title.png\"\n",
    "image_path = \"/Users/nshelton/Pictures/gundam4x.jpeg\"\n",
    "\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "print(image.shape)\n",
    "# image[:,:,1] = image[:,:,0]\n",
    "# image[:,:,2] = image[:,:,0]\n",
    "\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image_gray = cv2.resize(image_gray, (-1,-1), fx = 2, fy = 2)\n",
    " \n",
    "# filtered = image_gray\n",
    "sigma = 4\n",
    "min_canny = 4\n",
    "max_canny = 50\n",
    "filtered = canny(image_gray, sigma, min_canny, max_canny).astype(np.uint8) * 255\n",
    "\n",
    "cv2.imwrite(\"filtered.png\", filtered)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4659615.0 \t 4999\t\t\t\t\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# lines = probabilistic_hough_line(filtered, threshold=10, line_length=10, line_gap=2)\n",
    "\n",
    "# canny_lines_img = np.zeros(image.shape, np.uint8)\n",
    "# for line in lines:\n",
    "\n",
    "#     cv2.line(canny_lines_img, line[0], line[1], tuple(color), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "# cv2.imwrite(\"canny_lines.png\", canny_lines_img)\n",
    "\n",
    "\n",
    "# print(lines)\n",
    "\n",
    "all_strokes_raster = np.ones(image_gray.shape) * 255\n",
    "\n",
    "all_paths = []\n",
    "\n",
    "while len(all_paths) < 5000 and filtered.sum() > 1000:\n",
    "    print(filtered.sum(), \"\\t\", len(all_paths),  end=\"\\t\\t\\t\\r\")\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(filtered)\n",
    "\n",
    "    def placeStroke(input_raster, start):\n",
    "        img = input_raster.copy()\n",
    "        path = []\n",
    "        direction = np.pi\n",
    "        pos = np.array(start)\n",
    "\n",
    "        window = 1 \n",
    "        max_val =input_raster[start[1], start[0]]\n",
    "\n",
    "        while(max_val > 0):\n",
    "            min_val, max_val, min_loc, max_loc  = cv2.minMaxLoc(img[pos[1] - window:pos[1] + window +1, pos[0] - window:pos[0] + window +1])\n",
    "            pos += np.array(max_loc) - window \n",
    "            path.append(pos.copy())\n",
    "            cv2.circle(img, pos, window-1, 0, -1)\n",
    "\n",
    "        return path\n",
    "    \n",
    "    line_thickness = 2\n",
    "    def rasterStroke(dims, path) :\n",
    "        img = np.zeros(dims)\n",
    "        for i in range(len(path)-1):\n",
    "            a = (round(path[i][0]) , round(path[i][1]) )\n",
    "            b = (round(path[i+1][0]) , round(path[i+1][1]) )\n",
    "            cv2.line(img, a, b, 1, line_thickness, cv2.LINE_AA)\n",
    "            \n",
    "        return img\n",
    "\n",
    "    \n",
    "    new_stroke = placeStroke(filtered, max_loc)\n",
    "    all_paths.append(new_stroke)\n",
    "    stroke_raster = rasterStroke(image_gray.shape, new_stroke)\n",
    "\n",
    "    filtered = filtered - stroke_raster * 255\n",
    "    filtered = np.clip(filtered, 0, 255)\n",
    "    all_strokes_raster = np.clip(all_strokes_raster.astype(np.int32) - stroke_raster.astype(np.int32) * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # cv2.imwrite(\"current_stroke.png\",  (all_strokes_raster).astype(np.uint8))\n",
    "    # cv2.imwrite(\"filtered.png\", filtered)\n",
    "cv2.imwrite(\"current_stroke.png\",  (all_strokes_raster).astype(np.uint8))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "upscale = 10\n",
    "\n",
    "def plotPaths(paths, path_scale=1):\n",
    "    img = np.ones((297 * upscale, 420 * upscale, 3), np.uint8) * 255\n",
    "    img = np.zeros((297 * upscale, 420 * upscale, 3), np.uint8) \n",
    "\n",
    "    for path in paths:\n",
    "\n",
    "        color = (128 * int(random.random() * 2), 128 * int(random.random() * 2), 128 * int(random.random() * 2))\n",
    "        # color = (255,255,255)\n",
    "        for i in range(len(path) - 1):\n",
    "            a = (\n",
    "                round(path[i][0] * upscale * path_scale),\n",
    "                round(path[i][1] * upscale * path_scale)\n",
    "            )\n",
    "            \n",
    "            b = (\n",
    "                round(path[i + 1][0] * upscale * path_scale),\n",
    "                round(path[i + 1][1] * upscale * path_scale)\n",
    "            )\n",
    "\n",
    "            cv2.line(img, a, b, color, 1, cv2.LINE_AA)\n",
    "        \n",
    "        for i in range(len(path)):\n",
    "            a = (\n",
    "                round(path[i][0] * upscale * path_scale),\n",
    "                round(path[i][1] * upscale * path_scale),\n",
    "            )\n",
    "            img[a[1], a[0]] = [0,255,0]\n",
    "\n",
    "        if False:\n",
    "            for p in path:\n",
    "                a = (round(p[0] * upscale * path_scale), round(p[1] * upscale * path_scale))\n",
    "                if a[0] < img.shape[1] and a[1] < img.shape[0]:\n",
    "                    img[a[1], a[0], 0] = 255\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# connect_close_paths(path_list)\n",
    "path_list = [[p.tolist() for p in path] for path in all_paths]\n",
    "render_img = plotPaths(path_list, 0.03)\n",
    "cv2.imwrite(\"render.png\", render_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4009/5000 [00:47<00:11, 84.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged to 991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "\n",
    "def merge_one_path_kd(paths, threshold = 5):\n",
    "    points = []\n",
    "    for i in range(len(paths)):\n",
    "        points.append(paths[i][0])\n",
    "        points.append(paths[i][-1])\n",
    "\n",
    "    tree = KDTree(points)\n",
    "    \n",
    "\n",
    "    for i in range(len(paths)):\n",
    "        end_point = paths[i][-1]\n",
    "\n",
    "        distance, idx = tree.query(end_point, k=2)\n",
    "        other_idx = idx[1] // 2\n",
    "        other_is_front = idx[1] %2 == 0\n",
    "        if distance[1] < threshold and other_idx != i:\n",
    "\n",
    "            other_path = paths[other_idx]\n",
    "            if other_is_front: \n",
    "                paths[i] = paths[i] + other_path\n",
    "                paths.pop(other_idx)\n",
    "                break\n",
    "            else:\n",
    "                paths[i] = paths[i] + other_path[::-1]\n",
    "                paths.pop(other_idx)\n",
    "                break\n",
    "\n",
    "        start_point = paths[i][0]\n",
    "            \n",
    "        distance, idx = tree.query(start_point, k=2)\n",
    "        other_idx = idx[1] // 2\n",
    "        other_is_front = idx[1] %2 == 0\n",
    "        if distance[1] < threshold and other_idx != i:\n",
    "\n",
    "            other_path = paths[other_idx]\n",
    "            if other_is_front: \n",
    "                paths[i] = other_path[::-1] + paths[i]\n",
    "                paths.pop(other_idx)\n",
    "                break\n",
    "            else:\n",
    "                paths[i] = other_path + paths[i]\n",
    "                paths.pop(other_idx)\n",
    "                break\n",
    "\n",
    "    return paths\n",
    "\n",
    "def merge_one_path(paths, threshold = 5):\n",
    "\n",
    "    for i in range(len(paths)):\n",
    "        for j in range(len(paths)):\n",
    "            if i == j: continue\n",
    "\n",
    "            start1, end1 = paths[i][0], paths[i][-1]\n",
    "            start2, end2 = paths[j][0], paths[j][-1]\n",
    "\n",
    "            if (np.linalg.norm(np.array(end1) - np.array(start2)) < threshold ):\n",
    "                new_paths = [paths[k] for k in range(len(paths)) if k!=i and k!=j]\n",
    "                new_paths.append(paths[i]+paths[j])\n",
    "                return new_paths\n",
    "\n",
    "            if (np.linalg.norm(np.array(start1) - np.array(start2)) < threshold ):\n",
    "                new_paths = [paths[k] for k in range(len(paths)) if k!=i and k!=j]\n",
    "                new_paths.append(paths[i][::-1]+paths[j])\n",
    "                return new_paths\n",
    "\n",
    "            if (np.linalg.norm(np.array(end1) - np.array(end2)) < threshold ):\n",
    "                new_paths = [paths[k] for k in range(len(paths)) if k!=i and k!=j]\n",
    "                new_paths.append(paths[i]+paths[j][::-1])\n",
    "                return new_paths\n",
    "\n",
    "            if (np.linalg.norm(np.array(start1) - np.array(end2)) < threshold ):\n",
    "                new_paths = [paths[k] for k in range(len(paths)) if k!=i and k!=j]\n",
    "                new_paths.append(paths[j] + paths[i])\n",
    "                return new_paths\n",
    "            \n",
    "\n",
    "    return paths\n",
    "\n",
    "def close_loops(paths, threshold = 10):\n",
    "\n",
    "    for i in range(len(paths)):\n",
    "            start1, end1 = paths[i][0], paths[i][-1]\n",
    "            if (np.linalg.norm(np.array(start1) - np.array(end1)) < threshold ):\n",
    "                paths[i].append(start1)\n",
    "    return paths\n",
    "\n",
    "def smooth_closed_path(points, window_size=10):\n",
    "    points_array = np.array(points)\n",
    "    num_points = len(points)\n",
    "    smoothed_points = []\n",
    "\n",
    "    for i in range(num_points):\n",
    "        # Calculate the indices for the moving window, considering wrap-around\n",
    "        indices = [(i + j - window_size // 2) % num_points for j in range(window_size)]\n",
    "        window_points = points_array[indices]\n",
    "        avg_point = np.mean(window_points, axis=0)\n",
    "        smoothed_points.append(avg_point)\n",
    "\n",
    "    return smoothed_points\n",
    "\n",
    "def smooth_path(points, window_size=2):\n",
    "    points_array = np.array(points)\n",
    "    smoothed_points = []\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        start = max(0, i - window_size // 2)\n",
    "        end = min(len(points), i + window_size // 2 + 1)\n",
    "        window_points = points_array[start:end]\n",
    "        avg_point = np.mean(window_points, axis=0)\n",
    "        smoothed_points.append(avg_point)\n",
    "\n",
    "    return smoothed_points\n",
    "\n",
    "def smooth_all_2(paths, amount = 0.5) :\n",
    "    smoothed_paths = []\n",
    "\n",
    "    for k in range(len(paths)):\n",
    "        smoothed = [paths[k][0]]\n",
    "        for i in range(1, len(paths[k])-1):\n",
    "            target = (paths[k][i-1]+paths[k][i+1])/2\n",
    "            smoothed.append(paths[k][i] * (1 - amount) + target * amount)\n",
    "        smoothed.append(paths[k][-1])\n",
    "\n",
    "        path_is_closed =  np.array_equal(paths[k][0], paths[k][-1])\n",
    "        \n",
    "        if (path_is_closed):\n",
    "            target = (paths[k][1]+paths[k][-2])/2\n",
    "            smoothed[0] = smoothed[0] * (1 - amount) + target * amount\n",
    "            smoothed[-1] = smoothed[0] \n",
    "        smoothed_paths.append(np.array(smoothed))\n",
    "    \n",
    "    return smoothed_paths\n",
    "\n",
    "def smooth_all(paths, amount = 0.5) :\n",
    "    result = []\n",
    "    for path in paths:\n",
    "        path = np.array(path)\n",
    " \n",
    "        if np.all(path[0] == path[-1]) : \n",
    "            result.append(smooth_closed_path(path))\n",
    "        else:\n",
    "            result.append(smooth_path(path))\n",
    "    return result\n",
    "\n",
    "def simplify_all(paths, threshold=0):\n",
    "    for i in range(len(path_list)):\n",
    "        paths[i] = rdp(paths[i], threshold)\n",
    "    return (paths)\n",
    "\n",
    "def rdp(points, epsilon):\n",
    "    \"\"\"\n",
    "    Simplifies a path using the Ramer-Douglas-Peucker algorithm.\n",
    "\n",
    "    :param points: List of 2D points.\n",
    "    :param epsilon: Distance threshold for simplification.\n",
    "    :return: Simplified list of 2D points.\n",
    "    \"\"\"\n",
    "    points = np.array(points)\n",
    "\n",
    "    # Find the point with the maximum distance from the line formed by the first and last points\n",
    "    dmax = 0\n",
    "    index = 0\n",
    "    end = len(points)\n",
    "    for i in range(1, end - 1):\n",
    "        d = perpendicular_distance(points[i], points[0], points[-1])\n",
    "        if d > dmax:\n",
    "            index = i\n",
    "            dmax = d\n",
    "\n",
    "    # If the maximum distance is greater than epsilon, recursively simplify\n",
    "    if dmax > epsilon:\n",
    "        # Recursive call\n",
    "        results1 = rdp(points[:index+1], epsilon)\n",
    "        results2 = rdp(points[index:], epsilon)\n",
    "\n",
    "        # Build the result list\n",
    "        result = np.vstack((results1[:-1], results2))\n",
    "    else:\n",
    "        result = np.array([points[0], points[-1]])\n",
    "\n",
    "    return result\n",
    "\n",
    "def perpendicular_distance(point, line_start, line_end):\n",
    "    \"\"\"\n",
    "    Calculate the perpendicular distance from a point to a line.\n",
    "\n",
    "    :param point: The point (x, y).\n",
    "    :param line_start: The start of the line (x, y).\n",
    "    :param line_end: The end of the line (x, y).\n",
    "    :return: The perpendicular distance.\n",
    "    \"\"\"\n",
    "    if np.array_equal(line_start, line_end):\n",
    "        return np.linalg.norm(point - line_start)\n",
    "    else:\n",
    "        return np.linalg.norm(np.cross(line_end - line_start, line_start - point)) / np.linalg.norm(line_end - line_start)\n",
    "\n",
    "path_list = [[p.tolist() for p in path] for path in all_paths]\n",
    "\n",
    "print(len(path_list))\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(path_list))):\n",
    "    len_before = len(path_list)\n",
    "    path_list = merge_one_path_kd(path_list)\n",
    "    if len_before == len(path_list):\n",
    "        break\n",
    "\n",
    "print(\"merged to\", len(path_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed loops 991\n",
      "smoothed 1 991\n",
      "simplify_all 1 991\n",
      "smoothed 2 991\n",
      "simplify 2 991\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_list = close_loops(path_list)\n",
    "\n",
    "print(\"closed loops\", len(path_list))\n",
    "\n",
    "path_list  = [np.array(path) for path in path_list]\n",
    "\n",
    "for _ in range(1):\n",
    "    path_list = smooth_all_2(path_list, 0.2)\n",
    "\n",
    "print(\"smoothed 1\", len(path_list))\n",
    "\n",
    "path_list = simplify_all(path_list, 0.001)\n",
    "\n",
    "print(\"simplify_all 1\", len(path_list))\n",
    "\n",
    "for _ in range(1):\n",
    "    path_list = smooth_all_2(path_list, 0.5)\n",
    "\n",
    "print(\"smoothed 2\", len(path_list))\n",
    "\n",
    "path_list = simplify_all(path_list, 0.1)\n",
    "print(\"simplify 2\", len(path_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_img = plotPaths(path_list, 0.05)\n",
    "cv2.imwrite(\"render.png\", render_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import json\n",
    "import uuid\n",
    "\n",
    "projects_folder = \"/Users/nshelton/Hephaestus/projects\"\n",
    "\n",
    "def writePlot(paths):\n",
    "    dictionary = {\n",
    "        \"created_time\": \"4/7/2024 4:42:27 PM\",\n",
    "        \"modified_time\": \"4/7/2024 6:27:36 PM\",\n",
    "        \"camera_position\": [100, 100],\n",
    "        \"zoom\": 10.702,\n",
    "        \"aspect\": 0.563,\n",
    "        \"dom_element\": {},\n",
    "        \"plot_models\": [],\n",
    "    }\n",
    "\n",
    "    dictionary[\"plot_models\"].append(\n",
    "        {\n",
    "            \"position\": {\"x\": 0, \"y\": 0},\n",
    "            \"paths\": [path.tolist() for path in path_list],\n",
    "            \"scale\": 0.03,\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"state\": \"none\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    with open(projects_folder + \"/gundam.json\", \"w\") as outfile:\n",
    "        \n",
    "        json.dump(dictionary, outfile)\n",
    "\n",
    "\n",
    "writePlot(path_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
